{
 "metadata": {
  "kernelspec": {
   "language": "python",
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.13",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "sourceId": 8076,
     "databundleVersionId": 44219,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 31090,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook",
   "isGpuEnabled": true
  }
 },
 "nbformat_minor": 4,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "code",
   "source": "!pip install transformers\n!pip install tensorboard",
   "metadata": {
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-09-29T17:53:53.660254Z",
     "iopub.execute_input": "2025-09-29T17:53:53.660509Z",
     "iopub.status.idle": "2025-09-29T17:54:02.490575Z",
     "shell.execute_reply.started": "2025-09-29T17:53:53.660491Z",
     "shell.execute_reply": "2025-09-29T17:54:02.489815Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.52.4)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\nRequirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.33.1)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (25.0)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.4)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.2)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\nRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.5.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.14.0)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.1.5)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2.4.1)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.6.15)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->transformers) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: tensorboard in /usr/local/lib/python3.11/dist-packages (2.18.0)\nRequirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (1.4.0)\nRequirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (1.73.1)\nRequirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (3.8.2)\nRequirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (1.26.4)\nRequirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorboard) (25.0)\nRequirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (3.20.3)\nRequirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (75.2.0)\nRequirement already satisfied: six>1.9 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (1.17.0)\nRequirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (0.7.2)\nRequirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (3.1.3)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.12.0->tensorboard) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.12.0->tensorboard) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.12.0->tensorboard) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.12.0->tensorboard) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.12.0->tensorboard) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.12.0->tensorboard) (2.4.1)\nRequirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard) (3.0.2)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.12.0->tensorboard) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.12.0->tensorboard) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.12.0->tensorboard) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.12.0->tensorboard) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.12.0->tensorboard) (2024.2.0)\n",
     "output_type": "stream"
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "source": [
    "import os\n",
    "from sklearn.metrics import f1_score\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "from torch.optim import AdamW\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    ")\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datasets import Dataset\n",
    "import wandb\n",
    "import warnings\n",
    "from datasets import Sequence, Value"
   ],
   "metadata": {
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2025-09-29T08:51:16.614731Z",
     "start_time": "2025-09-29T08:51:16.572322Z"
    },
    "execution": {
     "iopub.status.busy": "2025-09-29T17:54:02.492503Z",
     "iopub.execute_input": "2025-09-29T17:54:02.492772Z",
     "iopub.status.idle": "2025-09-29T17:54:47.225790Z",
     "shell.execute_reply.started": "2025-09-29T17:54:02.492747Z",
     "shell.execute_reply": "2025-09-29T17:54:47.225284Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "text": "2025-09-29 17:54:22.320102: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1759168462.682114      36 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1759168462.787955      36 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
     "output_type": "stream"
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "source": "! unzip ../input/jigsaw-toxic-comment-classification-challenge/train.csv.zip;\n! unzip ../input/jigsaw-toxic-comment-classification-challenge/sample_submission.csv.zip;\n! unzip ../input/jigsaw-toxic-comment-classification-challenge/test.csv.zip;\n! unzip ../input/jigsaw-toxic-comment-classification-challenge/test_labels.csv.zip;",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-09-29T17:54:47.226546Z",
     "iopub.execute_input": "2025-09-29T17:54:47.226749Z",
     "iopub.status.idle": "2025-09-29T17:54:49.436197Z",
     "shell.execute_reply.started": "2025-09-29T17:54:47.226734Z",
     "shell.execute_reply": "2025-09-29T17:54:49.435467Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": "Archive:  ../input/jigsaw-toxic-comment-classification-challenge/train.csv.zip\n  inflating: train.csv               \nArchive:  ../input/jigsaw-toxic-comment-classification-challenge/sample_submission.csv.zip\n  inflating: sample_submission.csv   \nArchive:  ../input/jigsaw-toxic-comment-classification-challenge/test.csv.zip\n  inflating: test.csv                \nArchive:  ../input/jigsaw-toxic-comment-classification-challenge/test_labels.csv.zip\n  inflating: test_labels.csv         \n",
     "output_type": "stream"
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "source": [
    "TRAIN_PATH = '/kaggle/working/train.csv'\n",
    "VAL_PATH = '/kaggle/working/test.csv'\n",
    "\n",
    "MODEL_NAME = \"unitary/toxic-bert\"\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "VALID_SIZE = 0.2\n",
    "TARGET_COL = [\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]\n",
    "SAMPLE_COL = 'comment_text'\n",
    "BATCH_SIZE = 32\n",
    "NUM_LABELS = 6\n",
    "EPOCHS = 30\n",
    "PATIENCE = 10\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-29T08:29:03.098372Z",
     "start_time": "2025-09-29T08:29:03.088897Z"
    },
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-09-29T17:54:49.437990Z",
     "iopub.execute_input": "2025-09-29T17:54:49.438368Z",
     "iopub.status.idle": "2025-09-29T17:54:49.444012Z",
     "shell.execute_reply.started": "2025-09-29T17:54:49.438328Z",
     "shell.execute_reply": "2025-09-29T17:54:49.443228Z"
    }
   },
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "source": [
    "API_WANDB = os.getenv(\"WANDB_API_KEY\")\n",
    "wandb.login(key=API_WANDB)\n",
    "wandb.init(project=\"Bert-hf\", entity=\"detect_kaggle\")"
   ],
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-09-29T17:54:49.444937Z",
     "iopub.execute_input": "2025-09-29T17:54:49.445313Z",
     "iopub.status.idle": "2025-09-29T17:55:02.245685Z",
     "shell.execute_reply.started": "2025-09-29T17:54:49.445263Z",
     "shell.execute_reply": "2025-09-29T17:55:02.244901Z"
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": "df = pd.read_csv(TRAIN_PATH)\ndf = df.sample(frac=0.03, random_state=42)\n\ndf_train, df_valid = train_test_split(df, test_size=0.1, shuffle=True)\ntest_data = pd.read_csv(VAL_PATH)\ninference = pd.read_csv('/kaggle/working/sample_submission.csv')\n\nprint(\n    f'df train shape = {df_train.shape}\\n'\n    f'df valid shape = {df_valid.shape}\\n'\n    f'df test shape  = {test_data.shape}\\n'\n    f'df shape       = {df.shape}\\n'\n    f'length sum=bmit= {len(inference)}' \n    )",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-29T09:55:14.196891Z",
     "start_time": "2025-09-29T09:55:04.053501Z"
    },
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-09-29T17:55:02.246608Z",
     "iopub.execute_input": "2025-09-29T17:55:02.246959Z",
     "iopub.status.idle": "2025-09-29T17:55:04.255178Z",
     "shell.execute_reply.started": "2025-09-29T17:55:02.246934Z",
     "shell.execute_reply": "2025-09-29T17:55:04.254408Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": "df train shape = (4308, 8)\ndf valid shape = (479, 8)\ndf test shape  = (153164, 2)\ndf shape       = (4787, 8)\nlength sum=bmit= 153164\n",
     "output_type": "stream"
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "source": "# MAX_LEN = int(df.comment_text.str.split().apply(len).max()*1.5)\nMAX_LEN = int(df.comment_text.str.split().apply(len).max())\ndef preprocess_labels(dataframe, target_cols):\n    dataframe['labels'] = dataframe[target_cols].values.tolist()\n    return dataframe\n\ndf_train = preprocess_labels(df_train, TARGET_COL)\ndf_valid = preprocess_labels(df_valid, TARGET_COL)\n\ndf_train.drop(columns=TARGET_COL, inplace=True)\ndf_valid.drop(columns=TARGET_COL, inplace=True)\n\ndf_train",
   "metadata": {
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2025-09-29T09:55:20.201165Z",
     "start_time": "2025-09-29T09:55:14.372037Z"
    },
    "execution": {
     "iopub.status.busy": "2025-09-29T17:55:04.257421Z",
     "iopub.execute_input": "2025-09-29T17:55:04.257657Z",
     "iopub.status.idle": "2025-09-29T17:55:04.344997Z",
     "shell.execute_reply.started": "2025-09-29T17:55:04.257641Z",
     "shell.execute_reply": "2025-09-29T17:55:04.344306Z"
    }
   },
   "outputs": [
    {
     "execution_count": 7,
     "output_type": "execute_result",
     "data": {
      "text/plain": "                      id                                       comment_text  \\\n10740   1c65ec4affb6ef0a  \"\\n\\n A Bit Short on Time \\n\\nHello J.delanoy....   \n123210  93248d52ef3776c9  wrestlecrap is never a good source the book is...   \n18048   2fac7f1c0cc1839c  Fuck you! You sadistic admin that orgasms when...   \n50370   86a4ecdc43c131f6  It would also appear from this edit that in or...   \n81236   d9512c20bef247f3  \"\\n\\nHow about \"\"lack of media attention\"\" giv...   \n...                  ...                                                ...   \n54371   91480cba1d94ff98                            with four tildes (~~~~)   \n55328   93cccd5620761085  What do you know about schools in Lincolnshire...   \n151300  7ad5a8b3e2bc5693  Nirmal\\n\\nNirmal,\\n\\n12 FEB, 2012\\n\\nSubject: ...   \n71906   c087d58f290aa48e  Re: Template:Did you know nominations/2014 Nat...   \n74394   c7086a3af27bc8f7  Reverting constructive edits \\n\\nWhy are you r...   \n\n                    labels  \n10740   [0, 0, 0, 0, 0, 0]  \n123210  [0, 0, 0, 0, 0, 0]  \n18048   [1, 0, 1, 0, 1, 0]  \n50370   [0, 0, 0, 0, 0, 0]  \n81236   [0, 0, 0, 0, 0, 0]  \n...                    ...  \n54371   [0, 0, 0, 0, 0, 0]  \n55328   [0, 0, 0, 0, 0, 0]  \n151300  [0, 0, 0, 0, 0, 0]  \n71906   [0, 0, 0, 0, 0, 0]  \n74394   [1, 0, 0, 0, 0, 0]  \n\n[4308 rows x 3 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>comment_text</th>\n      <th>labels</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>10740</th>\n      <td>1c65ec4affb6ef0a</td>\n      <td>\"\\n\\n A Bit Short on Time \\n\\nHello J.delanoy....</td>\n      <td>[0, 0, 0, 0, 0, 0]</td>\n    </tr>\n    <tr>\n      <th>123210</th>\n      <td>93248d52ef3776c9</td>\n      <td>wrestlecrap is never a good source the book is...</td>\n      <td>[0, 0, 0, 0, 0, 0]</td>\n    </tr>\n    <tr>\n      <th>18048</th>\n      <td>2fac7f1c0cc1839c</td>\n      <td>Fuck you! You sadistic admin that orgasms when...</td>\n      <td>[1, 0, 1, 0, 1, 0]</td>\n    </tr>\n    <tr>\n      <th>50370</th>\n      <td>86a4ecdc43c131f6</td>\n      <td>It would also appear from this edit that in or...</td>\n      <td>[0, 0, 0, 0, 0, 0]</td>\n    </tr>\n    <tr>\n      <th>81236</th>\n      <td>d9512c20bef247f3</td>\n      <td>\"\\n\\nHow about \"\"lack of media attention\"\" giv...</td>\n      <td>[0, 0, 0, 0, 0, 0]</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>54371</th>\n      <td>91480cba1d94ff98</td>\n      <td>with four tildes (~~~~)</td>\n      <td>[0, 0, 0, 0, 0, 0]</td>\n    </tr>\n    <tr>\n      <th>55328</th>\n      <td>93cccd5620761085</td>\n      <td>What do you know about schools in Lincolnshire...</td>\n      <td>[0, 0, 0, 0, 0, 0]</td>\n    </tr>\n    <tr>\n      <th>151300</th>\n      <td>7ad5a8b3e2bc5693</td>\n      <td>Nirmal\\n\\nNirmal,\\n\\n12 FEB, 2012\\n\\nSubject: ...</td>\n      <td>[0, 0, 0, 0, 0, 0]</td>\n    </tr>\n    <tr>\n      <th>71906</th>\n      <td>c087d58f290aa48e</td>\n      <td>Re: Template:Did you know nominations/2014 Nat...</td>\n      <td>[0, 0, 0, 0, 0, 0]</td>\n    </tr>\n    <tr>\n      <th>74394</th>\n      <td>c7086a3af27bc8f7</td>\n      <td>Reverting constructive edits \\n\\nWhy are you r...</td>\n      <td>[1, 0, 0, 0, 0, 0]</td>\n    </tr>\n  </tbody>\n</table>\n<p>4308 rows × 3 columns</p>\n</div>"
     },
     "metadata": {}
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "source": [
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "\n",
    "train_dataset = Dataset.from_pandas(df_train)\n",
    "valid_dataset = Dataset.from_pandas(df_valid)\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(\n",
    "        examples[SAMPLE_COL],\n",
    "        padding='max_length',\n",
    "        truncation=True\n",
    "    )\n",
    "\n",
    "train_dataset = train_dataset.map(\n",
    "    tokenize_function,\n",
    "    batched=True,\n",
    "    remove_columns=SAMPLE_COL,\n",
    ")\n",
    "valid_dataset = valid_dataset.map(\n",
    "    tokenize_function,\n",
    "    batched=True,\n",
    "    remove_columns=SAMPLE_COL,\n",
    ")\n",
    "\n",
    "train_dataset = train_dataset.cast_column(\"labels\", Sequence(Value(\"float32\")))\n",
    "valid_dataset = valid_dataset.cast_column(\"labels\", Sequence(Value(\"float32\")))\n"
   ],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-29T09:58:04.091113Z",
     "start_time": "2025-09-29T09:55:20.703245Z"
    },
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-09-29T17:55:04.345783Z",
     "iopub.execute_input": "2025-09-29T17:55:04.346130Z",
     "iopub.status.idle": "2025-09-29T17:55:07.448235Z",
     "shell.execute_reply.started": "2025-09-29T17:55:04.346108Z",
     "shell.execute_reply": "2025-09-29T17:55:07.447572Z"
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "tokenizer_config.json:   0%|          | 0.00/174 [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c880fe74187c4cf39df0cc2738564a91"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "config.json:   0%|          | 0.00/811 [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6e143a6cb0f346b0a86474072bc6cbe7"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "vocab.txt: 0.00B [00:00, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "bcd235a364c0494abb13df7458b4ee29"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ef7bc581121249b5a5a559ef694148e0"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Map:   0%|          | 0/4308 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b6690f9a71ac4a2080e4213878138b4e"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Map:   0%|          | 0/479 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0db4e569c7014b59b0bb05e16b308bf5"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Casting the dataset:   0%|          | 0/4308 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c7230c799e244a2583e52d34526babff"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Casting the dataset:   0%|          | 0/479 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "203c1f266b7d49fd93b2482cf1a6cddc"
      }
     },
     "metadata": {}
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "source": "model = AutoModelForSequenceClassification.from_pretrained(\n    MODEL_NAME,\n    num_labels=NUM_LABELS,\n    ignore_mismatched_sizes=True,\n    problem_type=\"multi_label_classification\",\n)\n\n\ntraining_args = TrainingArguments(\n    per_device_train_batch_size=BATCH_SIZE,\n    per_device_eval_batch_size=BATCH_SIZE,\n    logging_strategy=\"epoch\",\n    eval_strategy=\"epoch\",\n    save_strategy=\"epoch\",\n    num_train_epochs=5,\n    logging_steps=25,\n    do_train=True,\n    do_eval=True,\n    report_to=[\"tensorboard\", \"wandb\"],\n)",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-29T10:04:20.527295Z",
     "start_time": "2025-09-29T10:04:13.127060Z"
    },
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-09-29T17:55:07.448987Z",
     "iopub.execute_input": "2025-09-29T17:55:07.449755Z",
     "iopub.status.idle": "2025-09-29T17:55:10.388511Z",
     "shell.execute_reply.started": "2025-09-29T17:55:07.449730Z",
     "shell.execute_reply": "2025-09-29T17:55:10.387654Z"
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "model.safetensors:   0%|          | 0.00/438M [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a6a90a3d0e6340ff816ac1ca295aa9f3"
      }
     },
     "metadata": {}
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    probs = 1 / (1 + np.exp(-logits))\n",
    "    preds = (probs > 0.5).astype(int)    \n",
    "    return {\"f1\": f1_score(labels, preds, average=\"macro\")}\n",
    "\n",
    "\n",
    "optimizer = AdamW([\n",
    "    {'params': list(model.bert.parameters()), 'lr': 1e-5},\n",
    "    {'params': list(model.classifier.parameters()), 'lr': 1e-3}\n",
    "])\n",
    "\n",
    "NUM_STEPS = int(EPOCHS*len(df_train)/BATCH_SIZE)\n",
    "\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer,\n",
    "    num_warmup_steps=int(0.1*NUM_STEPS),\n",
    "    num_training_steps=NUM_STEPS\n",
    ")"
   ],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-29T10:08:58.873535Z",
     "start_time": "2025-09-29T10:08:58.864862Z"
    },
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-09-29T17:55:10.389572Z",
     "iopub.execute_input": "2025-09-29T17:55:10.390046Z",
     "iopub.status.idle": "2025-09-29T17:55:10.397694Z",
     "shell.execute_reply.started": "2025-09-29T17:55:10.390020Z",
     "shell.execute_reply": "2025-09-29T17:55:10.396816Z"
    }
   },
   "outputs": [],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "source": "trainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=train_dataset,\n    eval_dataset=valid_dataset,\n    optimizers=(optimizer, scheduler),\n    compute_metrics=compute_metrics,\n)",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-29T10:09:41.232646Z",
     "start_time": "2025-09-29T10:09:40.923442Z"
    },
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-09-29T17:55:10.398793Z",
     "iopub.execute_input": "2025-09-29T17:55:10.399091Z",
     "iopub.status.idle": "2025-09-29T17:55:11.160677Z",
     "shell.execute_reply.started": "2025-09-29T17:55:10.399067Z",
     "shell.execute_reply": "2025-09-29T17:55:11.159796Z"
    }
   },
   "outputs": [],
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "source": "trainer.train()\n\nmodel.save_pretrained(\"./best_model\")\ntokenizer.save_pretrained(\"./best_model\")",
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-09-29T10:09:51.210475Z"
    },
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-09-29T17:55:11.161529Z",
     "iopub.execute_input": "2025-09-29T17:55:11.162191Z",
     "iopub.status.idle": "2025-09-29T18:13:26.248734Z",
     "shell.execute_reply.started": "2025-09-29T17:55:11.162163Z",
     "shell.execute_reply": "2025-09-29T18:13:26.247904Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "text": "\u001B[34m\u001B[1mwandb\u001B[0m: \u001B[33mWARNING\u001B[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n",
     "output_type": "stream"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n    <div>\n      \n      <progress value='340' max='340' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [340/340 18:08, Epoch 5/5]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>F1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.023800</td>\n      <td>0.024229</td>\n      <td>0.582059</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.022200</td>\n      <td>0.023598</td>\n      <td>0.651051</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.020600</td>\n      <td>0.024554</td>\n      <td>0.709048</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.018000</td>\n      <td>0.025182</td>\n      <td>0.714800</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>0.015000</td>\n      <td>0.025207</td>\n      <td>0.726535</td>\n    </tr>\n  </tbody>\n</table><p>"
     },
     "metadata": {}
    },
    {
     "execution_count": 12,
     "output_type": "execute_result",
     "data": {
      "text/plain": "('./best_model/tokenizer_config.json',\n './best_model/special_tokens_map.json',\n './best_model/vocab.txt',\n './best_model/added_tokens.json',\n './best_model/tokenizer.json')"
     },
     "metadata": {}
    }
   ],
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "source": [
    "\n",
    "model.eval()\n",
    "\n",
    "sample_texts = test_data[\"comment_text\"].sample(10).tolist()\n",
    "\n",
    "enc = tokenizer(\n",
    "    sample_texts,\n",
    "    padding=True,\n",
    "    truncation=True,\n",
    "    max_length=MAX_LEN,\n",
    "    return_tensors=\"pt\"\n",
    ")\n",
    "enc = {k: v.to(DEVICE) for k, v in enc.items()}\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model(**enc)\n",
    "    probs = torch.sigmoid(outputs.logits)\n",
    "    preds = (probs > 0.5).int()\n",
    "\n",
    "for text, p, pred in zip(sample_texts, probs, preds):\n",
    "    print(\"Text:\", text)\n",
    "    print(\"Predicted probabilities:\")\n",
    "    for col, val in zip(TARGET_COL, p.cpu().numpy()):\n",
    "        print(f\"  {col}: {val:.3f}\")\n",
    "    print(\"Predicted labels:\")\n",
    "    for col, val in zip(TARGET_COL, pred.cpu().numpy()):\n",
    "        print(f\"  {col}: {val}\")\n",
    "    print(\"---\")\n"
   ],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-23T07:28:11.830258Z",
     "start_time": "2025-09-23T07:28:08.041549Z"
    },
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-09-29T18:46:08.232777Z",
     "iopub.execute_input": "2025-09-29T18:46:08.233473Z",
     "iopub.status.idle": "2025-09-29T18:46:08.587669Z",
     "shell.execute_reply.started": "2025-09-29T18:46:08.233450Z",
     "shell.execute_reply": "2025-09-29T18:46:08.587040Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": "Text: ==You== \n Kiss my ass, bitch.\nPredicted probabilities:\n  toxic: 0.999\n  severe_toxic: 0.244\n  obscene: 0.998\n  threat: 0.000\n  insult: 0.975\n  identity_hate: 0.051\nPredicted labels:\n  toxic: 1\n  severe_toxic: 0\n  obscene: 1\n  threat: 0\n  insult: 1\n  identity_hate: 0\n---\nText: \" \n\n == Edit Request:Periyar as atheist == \n First of all, thanks for answering my question. \n\n But why should Periyar's views on Islam and Christianity be in Controversies section? On more than one occasion, Periyar has critized organized religions including Islam and Christianity. Is'nt Periyar's statement \"\" Bane of Tamizhians is Brahmins, Muslims and Christians consider themselves to Tamizhians\"\" correct place the \"\"Religion and Atheism section? \n\n Below two statements which are the author's own conclusion portray Periyar as favoring Christianity and Islam. \n\n Periyar viewed Christianity similar to the monotheistic faith of Islam. He explained that their faith says that there can be only one God which has no name or shape. Periyar took an interest in Rev. Martin Luther, where both he and his followers wanted to liken him and his role to that of the European reformer. Thus, Christian views such as that of Ram Mohan Roy's The Precepts of Jesus has had at least an indirect influence on Periyar. \n\n Anita Diehl.(1977) \"\"Personal View of the author\"\" According to him, the first duty of a government is to run the social organisation efficiently, and that the philosophy of religion was to organise the social system. Periyar pointed out that while Christian and Islamic religions were fulfilling this role, the Hindu religion remained totally unsuitable for social progress. \n\n Saraswathi. Towards Self-Respect \n\n Just like Periyar's role as Dharmakartha of Hindu temples and Periyar's not cooking non-vegeteraian food for over a month for accomodating Marimalai Adigalar cannot be construed as his consideration for Hindu religion, the above two statements which are author's self views should removed.\"\nPredicted probabilities:\n  toxic: 0.000\n  severe_toxic: 0.000\n  obscene: 0.000\n  threat: 0.000\n  insult: 0.000\n  identity_hate: 0.000\nPredicted labels:\n  toxic: 0\n  severe_toxic: 0\n  obscene: 0\n  threat: 0\n  insult: 0\n  identity_hate: 0\n---\nText: According to  Enterbrain, the PS3 sold 183,217 units in November in Japan, outselling the Wii’s 159,193 consoles. while this isn't an enormous amount, it is notable since this is the first month the PS3 has beaten the Wii in sales.\nPredicted probabilities:\n  toxic: 0.000\n  severe_toxic: 0.000\n  obscene: 0.000\n  threat: 0.000\n  insult: 0.000\n  identity_hate: 0.000\nPredicted labels:\n  toxic: 0\n  severe_toxic: 0\n  obscene: 0\n  threat: 0\n  insult: 0\n  identity_hate: 0\n---\nText: (outdent) \n\n I have replied to this issue in the previous section. The first edit that was objected to http://en.wikipedia.org/w/index.php?title=Public_health_insurance_option&diff;=prev&oldid;=323214537 should be reinstated. It avoids the need to quote precisely what Grassley said and how he said it. The source for this is as good as any other found in this and other WP articles on U.S. health care, coming from a respected think tank.\nPredicted probabilities:\n  toxic: 0.000\n  severe_toxic: 0.000\n  obscene: 0.000\n  threat: 0.000\n  insult: 0.000\n  identity_hate: 0.000\nPredicted labels:\n  toxic: 0\n  severe_toxic: 0\n  obscene: 0\n  threat: 0\n  insult: 0\n  identity_hate: 0\n---\nText: \" \n\n ::::Sorry, imdx80. There has been a lot of vandalism of this article, seemingly from someone with some sort of grudge (perceived or otherwise) against DeVito. Speaking for myself, I suspected that the image might have been part of that. It was supposition only, and I probably should have left that out of my earlier comment. \n ::::As much as your contributions are appreciated (and I hope you continue to contribute to Wikipedia), I personally just didn't feel it was a represenative image of DeVito, and for other reasons I stated above, felt it should go. Since others had already made the same opinion known, I removed it. \n ::::There are few \"\"professionals\"\" here. I hope you stick around with us amateurs.   \"\nPredicted probabilities:\n  toxic: 0.000\n  severe_toxic: 0.000\n  obscene: 0.000\n  threat: 0.000\n  insult: 0.000\n  identity_hate: 0.000\nPredicted labels:\n  toxic: 0\n  severe_toxic: 0\n  obscene: 0\n  threat: 0\n  insult: 0\n  identity_hate: 0\n---\nText: \" \n :Hi. Using the banner to trick others qualifies as a spoof of the MediaWiki interface, which is prohibited by WP:SMI. Please self-revert, now that you understand that what you are doing violates policy. Thanks,   \"\nPredicted probabilities:\n  toxic: 0.000\n  severe_toxic: 0.000\n  obscene: 0.000\n  threat: 0.000\n  insult: 0.000\n  identity_hate: 0.000\nPredicted labels:\n  toxic: 0\n  severe_toxic: 0\n  obscene: 0\n  threat: 0\n  insult: 0\n  identity_hate: 0\n---\nText: Michael Jackson got his perverted heredity from him.\nPredicted probabilities:\n  toxic: 0.942\n  severe_toxic: 0.000\n  obscene: 0.001\n  threat: 0.000\n  insult: 0.004\n  identity_hate: 0.002\nPredicted labels:\n  toxic: 1\n  severe_toxic: 0\n  obscene: 0\n  threat: 0\n  insult: 0\n  identity_hate: 0\n---\nText: fuck your fucking sandbox!\nPredicted probabilities:\n  toxic: 0.999\n  severe_toxic: 0.756\n  obscene: 0.999\n  threat: 0.001\n  insult: 0.981\n  identity_hate: 0.117\nPredicted labels:\n  toxic: 1\n  severe_toxic: 1\n  obscene: 1\n  threat: 0\n  insult: 1\n  identity_hate: 0\n---\nText: == Robert Horry== \n Hey asshole, I did not vandalize Horry's page. That nickname is what sportscenter called him after his hard flagrant foul.\nPredicted probabilities:\n  toxic: 0.963\n  severe_toxic: 0.005\n  obscene: 0.951\n  threat: 0.000\n  insult: 0.789\n  identity_hate: 0.006\nPredicted labels:\n  toxic: 1\n  severe_toxic: 0\n  obscene: 1\n  threat: 0\n  insult: 1\n  identity_hate: 0\n---\nText: hi all i want to say is it sucks and also it is boring why didn't you come to skool on tuesday\nPredicted probabilities:\n  toxic: 0.973\n  severe_toxic: 0.000\n  obscene: 0.140\n  threat: 0.000\n  insult: 0.005\n  identity_hate: 0.000\nPredicted labels:\n  toxic: 1\n  severe_toxic: 0\n  obscene: 0\n  threat: 0\n  insult: 0\n  identity_hate: 0\n---\n",
     "output_type": "stream"
    }
   ],
   "execution_count": 38
  },
  {
   "cell_type": "code",
   "source": "",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-23T07:22:40.837065Z",
     "start_time": "2025-09-23T07:22:40.764436Z"
    },
    "trusted": true
   },
   "outputs": [],
   "execution_count": null
  }
 ]
}
